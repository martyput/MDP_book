This chapter illustrates the rigorous formulation of Markov decision process models for a diverse set of applications: inventory management, Gridworld navigation, revenue management, queuing models, animal hunting behaviour, clinical decision making, appointment scheduling, optimal stopping, and sports strategy. Representing a sequential decision problem as a Markov decision process requires specifying five objects: decision epochs, states, actions, transition probabilities and rewards. This chapter shows how to do so in each of the applications. The objective of this chapter is to highlight both the wide applicability of the MDP framework and the diverse aspects of model formulation. Many of these examples are revisited in subsequent chapters.

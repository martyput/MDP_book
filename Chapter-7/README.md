 Chapter 7 covers infinite horizon Markov decision processes under the long-run average reward criterion. The average reward criterion applies to non-terminating systems in which decisions are made frequently and in perpetuity. These models pose numerous analytical challenges because the existence and structure of the average reward depends on the limiting properties of underlying Markov chains. Markov chain structure and its implications on the average reward model are discussed. The concepts of bias and gain are formalized and connections to the discounted model and total reward model are provided. The Bellman equation and its properties are presented. Value iteration, policy iteration and linear programming approaches are studied. The concept of relative value iteration is introduced. A brief discussion of structured policies is included. The chapter concludes with a case study of queuing service rate control, comparing solution algorithms. 
